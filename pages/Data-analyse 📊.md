## Hoe?##
- Algorithms
	- Given the availability of labeled data with known outcomes, supervised machine learning methods are appropriate and will be utilized.
	- Logistic regression will be used, as it provides an interpretable and fast starting point for binary classification. Decision trees will be performed for the same reasons, with the added benefit of visual interpretation.
	- Several ensemble models will also be used in the aim to capture complex patterns in the large dataset. Random forest, Gradient Boosting (XGBoost and LightGBM) and Support Vector Machines (SVM) will be applied.
- Class imbalance
	- An initial explorative analysis of the unmodified data revealed that 4,166 participants had 0 car accidents that year, while only 305 participants were involved in at least 1 automobile accident. To address this class imbalance, oversampling was chosen to avoid data loss. Specifically, due to its model-agnostic nature, Synthetic Minority Over-sampling Technique (SMOTE) will be applied in order to balance the dataset. This technique involves the selection of a random instance from the minority class. Subsequently, the k nearest neighbors of this instance are identified. One of these neighbors is then randomly selected, and a synthetic data point is generated between the original instance and the chosen neighbor at a randomly determined position within the feature space [[47]] . In this study, k-values between 3 and 5 will be tested. A known limitation of SMOTE is that synthetic minority-class examples are generated without accounting for the distribution of the majority class, which may result in ambiguous samples, particularly in regions where the classes strongly overlap [[48]]
- Feature importance
	- To ensure a consistent and interpretable comparison of feature importance across models, SHapley Additive exPlanations (SHAP) values will be used for all algorithms. This unified approach avoids biases inherent in model-specific importance metrics and provides a fair basis for evaluating the predictive relevance of features. SHAP is a model-agnostic interpretability method based on principles from cooperative game theory. It quantifies the contribution of each feature to a model’s prediction by fairly distributing the output among all input features, allowing for consistent and comparable estimates of feature importance across different machine learning algorithms. [[49]]. A beeswarm plot and mean SHAP plot will be provided to aid interpretability.
- Automobile accident prediction
	- In the second part of this study, the predictive performance of each model in identifying the occurrence of an automobile accident will be evaluated. Performance will be assessed using the mean values of accuracy, precision, recall, and F1-score, calculated through K-fold cross-validation (k = 10). Although SMOTE will be applied to address class imbalance, accuracy alone remains an inadequate metric. In imbalanced datasets, accuracy can be heavily skewed by the majority class, potentially overstating performance while failing to capture model effectiveness on the minority class. Therefore, a broader range of evaluation metrics will be used to provide a more nuanced and comprehensive assessment of model performance across both classes.
	- A comparison between the performance of different models will be depicted through a table, including mean score, standard deviation, minimum and maximum. Additionally, confusion matrixes (predicted vs true label) will be provided for each algorithm. All hyperparameters will be shared to enable replicability.
- Software and packages
	- All analyses in this study will be conducted using Python 3.11.12 (Python Software Foundation, 2025), a widely adopted programming language for scientific computing and machine learning. Model development will rely on the Scikit-learn library (Pedregosa et al., 2011), which provides all of the algorithms and tools need in this study for building and and evaluating the machine learning models. Numpy (Harris et al., 2020) will be used to handle multidimensional array structures and facilitate numerical computations, while Pandas will be used for data loading, exploration and manipulation. For data visualisation and result presentation, Matplotlib  (Hunter, J. D., 2007) and Seaborn (Waskom, M. L., 2021) will be employed to generate plots and summary tables. To adress class imbalance, SMOTE will be implemented using the Imbalanced-learn library (Lemaître et al., 2016), which relies on Scikit-learn. model interpretability will be achieved through SHAP, utilising the SHAP Python Library (Lundberg & Lee, 2016) to compute and visualise feature importance across models. The development environment selected is JupyterLab 4.4.2 (JupyterLab Development Team, 2024), chosen for its ease of use and ability to conveniently share code. Version control will be maintained through GIT (Git, n.d.), enabling systematic tracking of code changes. Both the dataset and associated code will be securely backed up locally and via the password-protected cloud storage service Pixiu (Vrije Universiteit Brussel – HPC Team, n.d.).
	- Citations
		- Python Software Foundation (2025). *Python (Version 3.11.12)* [Computer software]. https://www.python.org
		- Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., Blondel, M., Prettenhofer, P., Weiss, R., Dunbourg, V., Vanderplas, J., Passos, A., Cournapeau, D., Brucher, M., Perror, M. & Duchesnay, É. (2011). *Scikit-learn: Machine learning in Python*. *Journal of Machine Learning Research*, *12*, 2825–2830. https://www.jmlr.org/papers/volume12/pedregosa11a/pedregosa11a.pdf
		- Harris, C. R., Millman, K. J., van der Walt, S. J., Gommers, R., Virtanen, P., Cournapeau, D., Wieser, E., Taylor, J., Berg, S., Smith, N. J., Kern, R., Picus, M., Hoyer, S., van Kerkwijk, M. H., Brett, M., Haldane, A., DEl Río, J. F., Wiebe, M., Peterson, P., Gérard-Marchant, P., Sheppard, K., Reddy, T., Weckesser, W., Abbasi, H., Gohlke, C. & Oliphant, T. E. (2020). *Array programming with NumPy*. Nature, 585(7825), 357–362. https://doi.org/10.1038/s41586-020-2649-2
		- McKinney, W. (2010). Data structures for statistical computing in Python. *SciPy*, *445*(1), 51-56. https://doi.org/10.25080/Majora-92bf1922-00a
		- Hunter, J. D. (2007). *Matplotlib: A 2D graphics environment*. Computing in Science & Engineering, 9(3), 90–95. https://doi.org/10.1109/MCSE.2007.55
		- Waskom, M. L., (2021). seaborn: statistical data visualization. Journal of Open Source Software, 6(60), 3021. https://doi.org/10.21105/joss.03021
		- Lemaître, G., Nogueira, F., & Aridas, C. K. (2016). *Imbalanced-learn: A Python toolbox to tackle the curse of imbalanced datasets in machine learning*. *Journal of Machine Learning Research*, *18*(17), 1–5. https://doi.org/10.48550/arXiv.1609.06570
		- Lundberg, S. M., & Lee, S.-I. (2017). *A unified approach to interpreting model predictions*. In *Advances in Neural Information Processing Systems* (Vol. 30). https://github.com/slundberg/shap
		- JupyterLab Development Team. (2024). *JupyterLab (Version 4.4.2)* [Computer software]. https://jupyter.org
		- Git SCM. (n.d.). *Git*. https://git-scm.com/
		- Vrije Universiteit Brussel – HPC Team. (n.d.). *Pixiu: Secure research data management and backup service* [Computer software].https://hpc.vub.be/docs/pixiu/
-